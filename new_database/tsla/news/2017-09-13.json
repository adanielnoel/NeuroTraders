[
    {
        "time": "1:47PM UTC",
        "body": "WASHINGTON (Reuters) - The chairman of the U.S. National Transportation Safety Board (NTSB) said on Tuesday \u201coperational limitations\u201d in the Tesla Model S played a \u201cmajor role\u201d in a May 2016 crash that killed a driver using the vehicle\u2019s semi-autonomous \u201cAutopilot\u201d system.\n\nThe limits on the system include factors such as Tesla being unable to ensure driver attention even when the car is traveling at high speeds, ensuring Autopilot is used only on certain roads and monitoring driver engagement, NTSB said.\n\nThe NTSB recommended auto safety regulators and automakers take steps to ensure that semi-autonomous systems are not misused.\n\n\u201cSystem safeguards were lacking,\u201d NTSB Chairman Robert Sumwalt said. \u201cTesla allowed the driver to use the system outside of the environment for which it was designed and the system gave far too much leeway to the driver to divert his attention.\u201d\n\nTesla Inc (TSLA.O) said in a statement that \u201cAutopilot significantly increases safety,\u201d citing an earlier government study that suggested the system reduced the incidence of crashes.\n\nThe automaker said it would evaluate the NTSB\u2019s recommendations.\n\n\u201cWe will also continue to be extremely clear with current and potential customers that Autopilot is not a fully self-driving technology and drivers need to remain attentive at all times,\u201d Tesla said.\n\nJoshua Brown, a 40-year-old Ohio man, was killed near Williston, Florida, when his Model S collided with a truck while it was engaged in the \u201cAutopilot\u201d mode.\n\nThe incident raised questions about the safety of systems that can perform driving tasks for extended stretches of time with little or no human intervention, but which cannot completely replace human drivers.\n\nThe NTSB recommendations will put new pressure on regulators and automakers to deal with the limitations of driver-assistance technologies.\n\nIn its findings on Tuesday, the NTSB said the self-driving system\u2019s \u201coperational design\u201d was a contributing factor to the 2016 crash because it allows drivers to avoid steering or watching the road for lengthy periods of time that were \u201cinconsistent\u201d with warnings from Tesla.\n\nThe NTSB said Tesla could have taken further steps to prevent the system\u2019s misuse, and faulted the driver for not paying attention and for \u201coverreliance on vehicle automation.\u201d\n\nThe agency said the Autopilot system operated as designed but did not do enough to ensure drivers paid adequate attention. On some roads, drivers could use Autopilot at up to 90 miles (145 km) per hour, it said.\n\nTesla did not ensure that the system was used only on highways and limited-access roads, as recommended in the owner\u2019s manual, a fact that Sumwalt noted.\n\nThe NTSB recommended that automakers monitor driver attention in ways other than through detecting steering-wheel engagement.\n\nThe system could not reliably detect cross traffic and \u201cdid little to constrain the use of autopilot to roadways for which it was designed,\u201d the board said.\n\nMonitoring driver attention by measuring the driver\u2019s touching of the steering wheel \u201cwas a poor surrogate for monitored driving engagement,\u201d said the board.\n\nTesla said in June 2016 that Autopilot \u201cis not perfect and still requires the driver to remain alert.\u201d\n\nAt a public hearing Tuesday on the crash involving Brown, NTSB said the truck driver and the Tesla driver \u201chad at least 10 seconds to observe and respond to each other.\u201d\n\nBrown\u2019s family said on Monday the car was not to blame for the crash.\n\n\u201cWe heard numerous times that the car killed our son. That is simply not the case,\u201d the family\u2019s statement said. \u201cThere was a small window of time when neither Joshua nor the Tesla features noticed the truck making the left-hand turn in front of the car.\u201d\n\n\u201cPeople die every day in car accidents,\u201d the statement said. \u201cChange always comes with risks, and zero tolerance for deaths would totally stop innovation and improvements.\u201d\n\nA spokeswoman for Tesla and a lawyer for the family, Jack Landskroner, have declined to say if the automaker has reached a legal settlement with the Brown family.\n\nNTSB recommended that NHTSA require automakers to have safeguards to prevent the misuse of semi-autonomous vehicle features.\n\nThe National Highway Traffic Safety Administration (NHTSA) said it would review the findings of the safety board.\n\nIn January, NHTSA said it found no evidence of defects in the crash. NHTSA and NTSB said Brown did not apply the brakes, and his last action was to set the cruise control at 74 miles per hour (119 kph), less than 2 minutes before the crash - above the 65-mph speed limit.",
        "header": "UPDATE 4-'System safeguards' lacking in Tesla crash on autopilot -U.S. NTSB",
        "link": "http://www.reuters.com/article/tesla-autopilot/update-4-system-safeguards-lacking-in-tesla-crash-on-autopilot-u-s-ntsb-idUSL2N1LT0T4"
    },
    {
        "time": "9:42AM UTC",
        "body": "WASHINGTON, Sept 12 (Reuters) - The chairman of the U.S. National Transportation Safety Board (NTSB) said Tuesday \u201coperational limitations\u201d in the Tesla Model S played a \u201cmajor role\u201d in the May 2016 crash that killed a driver using the vehicle\u2019s semi-autonomous \u201cAutopilot\u201d system.\n\nReuters reported Monday that the NTSB is expected to find that the system was a contributing factor. The system is expected be labeled a contributing factor in the crash because it allowed drivers to avoid steering or watching the road for lengthy periods. (Reporting by David Shepardson; Editing by Chizu Nomiyama)",
        "header": "NTSB: 'operational limitations' played major rule in Tesla autopilot crash",
        "link": "http://www.reuters.com/article/tesla-autopilot/ntsb-operational-limitations-played-major-rule-in-tesla-autopilot-crash-idUSL2N1LT0S6"
    },
    {
        "time": "1:49PM UTC",
        "body": "WASHINGTON (Reuters) - The chairman of the U.S. National Transportation Safety Board (NTSB) said on Tuesday \u201coperational limitations\u201d in the Tesla Model S played a \u201cmajor role\u201d in a May 2016 crash that killed a driver using the vehicle\u2019s semi-autonomous \u201cAutopilot\u201d system.\n\nThe limits on the system include factors such as Tesla being unable to ensure driver attention even when the car is traveling at high speeds, ensuring Autopilot is used only on certain roads and monitoring driver engagement, NTSB said.\n\nThe NTSB recommended auto safety regulators and automakers take steps to ensure that semi-autonomous systems are not misused.\n\n\u201cSystem safeguards were lacking,\u201d NTSB Chairman Robert Sumwalt said. \u201cTesla allowed the driver to use the system outside of the environment for which it was designed and the system gave far too much leeway to the driver to divert his attention.\u201d\n\nTesla Inc (TSLA.O) said in a statement that \u201cAutopilot significantly increases safety,\u201d citing an earlier government study that suggested the system reduced the incidence of crashes.\n\nThe automaker said it would evaluate the NTSB\u2019s recommendations.\n\n\u201cWe will also continue to be extremely clear with current and potential customers that Autopilot is not a fully self-driving technology and drivers need to remain attentive at all times,\u201d Tesla said.\n\nJoshua Brown, a 40-year-old Ohio man, was killed near Williston, Florida, when his Model S collided with a truck while it was engaged in the \u201cAutopilot\u201d mode.\n\nThe incident raised questions about the safety of systems that can perform driving tasks for extended stretches of time with little or no human intervention, but which cannot completely replace human drivers.\n\nThe NTSB recommendations will put new pressure on regulators and automakers to deal with the limitations of driver-assistance technologies.\n\nIn its findings on Tuesday, the NTSB said the self-driving system\u2019s \u201coperational design\u201d was a contributing factor to the 2016 crash because it allows drivers to avoid steering or watching the road for lengthy periods of time that were \u201cinconsistent\u201d with warnings from Tesla.\n\nThe NTSB said Tesla could have taken further steps to prevent the system\u2019s misuse, and faulted the driver for not paying attention and for \u201coverreliance on vehicle automation.\u201d\n\nThe agency said the Autopilot system operated as designed but did not do enough to ensure drivers paid adequate attention. On some roads, drivers could use Autopilot at up to 90 miles (145 km) per hour, it said.\n\nTesla did not ensure that the system was used only on highways and limited-access roads, as recommended in the owner\u2019s manual, a fact that Sumwalt noted.\n\nThe NTSB recommended that automakers monitor driver attention in ways other than through detecting steering-wheel engagement.\n\nThe system could not reliably detect cross traffic and \u201cdid little to constrain the use of autopilot to roadways for which it was designed,\u201d the board said.\n\nMonitoring driver attention by measuring the driver\u2019s touching of the steering wheel \u201cwas a poor surrogate for monitored driving engagement,\u201d said the board.\n\nTesla said in June 2016 that Autopilot \u201cis not perfect and still requires the driver to remain alert.\u201d\n\nAt a public hearing Tuesday on the crash involving Brown, NTSB said the truck driver and the Tesla driver \u201chad at least 10 seconds to observe and respond to each other.\u201d\n\nBrown\u2019s family said on Monday the car was not to blame for the crash.\n\n\u201cWe heard numerous times that the car killed our son. That is simply not the case,\u201d the family\u2019s statement said. \u201cThere was a small window of time when neither Joshua nor the Tesla features noticed the truck making the left-hand turn in front of the car.\u201d\n\n\u201cPeople die every day in car accidents,\u201d the statement said. \u201cChange always comes with risks, and zero tolerance for deaths would totally stop innovation and improvements.\u201d\n\nA spokeswoman for Tesla and a lawyer for the family, Jack Landskroner, have declined to say if the automaker has reached a legal settlement with the Brown family.\n\nNTSB recommended that NHTSA require automakers to have safeguards to prevent the misuse of semi-autonomous vehicle features.\n\nThe National Highway Traffic Safety Administration (NHTSA) said it would review the findings of the safety board.\n\nIn January, NHTSA said it found no evidence of defects in the crash. NHTSA and NTSB said Brown did not apply the brakes, and his last action was to set the cruise control at 74 miles per hour (119 kph), less than 2 minutes before the crash - above the 65-mph speed limit.",
        "header": "'System safeguards' lacking in Tesla crash on autopilot: NTSB",
        "link": "http://www.reuters.com/article/us-tesla-autopilot/system-safeguards-lacking-in-tesla-crash-on-autopilot-ntsb-idUSKCN1BN1QP"
    }
]